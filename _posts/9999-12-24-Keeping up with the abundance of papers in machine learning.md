---
layout: post
title:  "Keeping up with the abundance of papers in machine learning"
date:   2018-07-01 00:00:00 -0500
description: "As a popular field that sparks a lot of interest and therefore is given a lot of funding, machine learning and especially deep learning is the topic of a prodigious amount of research papers. In this article I will present my personal techniques to keep up and introduce tools I employ daily to keep up." 
published: false
---

# Keeping up with the abundance of papers in machine learning

As a popular field that sparks a lot of interest and therefore is given a lot of funding, machine learning and especially deep learning is the topic of a prodigious amount of research papers. In this article I will present my personal techniques to keep up and introduce tools I employ daily to keep up.

## Focus on a field

While this is optional and probably something people might disagree with, I would recommend focusing on a field. It can be very wide like "Computer Vision" or very targeted like "Text Recognition", but having a precise topic of interest will allow for an easier accumulation of knowledge and up to a certain extent, a greater ability to keep track of the subfield evolution. It never hurts to peak over the other field obviously, but switching from clustering to music generation while also...

## Check the references

A recurrent personal mistake of mine is to gloss over something unknown to me and keep reading. While that works from time to time. It usually ends up being a poor decision if your goal is learning. Recently while reading a rather new paper [NRTR: A No-Recurrence Sequence-to-Sequence Model For Scene Text Recognition](https://arxiv.org/pdf/1806.00926.pdf) they mentionned that their architecture was based on transformer, that was introduced in [Attention is all you need](https://arxiv.org/abs/1706.03762). Reading the latter helped greatly with some key concepts in the former.  

## Use Arxiv-sanity-preserver (https://github.com/karpathy/arxiv-sanity-preserver)

This is a well known tool, created by Andrej Karpathy as "a web interface that attempts to tame the overwhelming flood of papers on Arxiv". It is packed with features like sorting by popularity ("hype") which is based on retweet, and a very useful *Recommended* tab which picks papers similar the one 

## Read to feed your curiosity

Unless you have a insane level of discipline you will not read a paper a day if you hate it. So above all else (especially what I wrote above), read 